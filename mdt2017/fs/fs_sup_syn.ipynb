{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "with open(\"wikicorpus_01\") as myfile:\n",
    "    head = list(islice(myfile, 5651))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Néstor_Gabriel_Martinena néstor_gabriel_martinena NP00000 0\\n', '( ( Fpa 0\\n', 'La el DA0FS0 0\\n', 'Plata plata NP00000 10501473\\n', ', , Fc 0\\n', 'Buenos_Aires buenos_aires NP00000 0\\n', ', , Fc 0\\n', 'Argentina argentina NP00000 02035234\\n', ', , Fc 0\\n']\n"
     ]
    }
   ],
   "source": [
    "print(head[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = []\n",
    "for s in head:\n",
    "    sent.append(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Néstor_Gabriel_Martinena', 'néstor_gabriel_martinena', 'NP00000', '0'],\n",
       " ['(', '(', 'Fpa', '0'],\n",
       " ['La', 'el', 'DA0FS0', '0'],\n",
       " ['Plata', 'plata', 'NP00000', '10501473'],\n",
       " [',', ',', 'Fc', '0']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "sentences = []\n",
    "for s in sent:\n",
    "    if len(s) == 4 and s[0] not in {'(', ')', ','} and '[' not in s[1]:\n",
    "        words.append((s[1], s[2], s[3]))\n",
    "        #if 'endofarticle' in s[1]:\n",
    "        #    sentences.append(words)\n",
    "        #    words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = dict()\n",
    "for fst,snd,trd in words:\n",
    "    if fst not in count:\n",
    "        count[fst] = 1\n",
    "    else:\n",
    "        count[fst] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count['entrar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('néstor_gabriel_martinena', 'NP00000', '0'),\n",
       " ('el', 'DA0FS0', '0'),\n",
       " ('plata', 'NP00000', '10501473'),\n",
       " ('buenos_aires', 'NP00000', '0')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = []\n",
    "check = []\n",
    "for fst,snd,trd in words:\n",
    "    aux.append((fst,snd, trd))\n",
    "    if fst == '.':\n",
    "        check.append(aux)\n",
    "        aux = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('néstor_gabriel_martinena', 'NP00000', '0'),\n",
       "  ('el', 'DA0FS0', '0'),\n",
       "  ('plata', 'NP00000', '10501473'),\n",
       "  ('buenos_aires', 'NP00000', '0'),\n",
       "  ('argentina', 'NP00000', '02035234'),\n",
       "  ('ser', 'VSIP3S0', '01775973'),\n",
       "  ('uno', 'DI0MS0', '0'),\n",
       "  ('futbolista', 'NCCS000', '0'),\n",
       "  ('argentino', 'AQ0MS0', '00278090'),\n",
       "  ('.', 'Fp', '0')],\n",
       " [('jugar', 'VMM02S0', '00727813'),\n",
       "  ('de', 'SPS00', '0'),\n",
       "  ('delantero', 'NCMS000', '00466114'),\n",
       "  ('y', 'CC', '0'),\n",
       "  ('su', 'DP3CS0', '0'),\n",
       "  ('equipo', 'NCMS000', '06093198'),\n",
       "  ('actual', 'AQ0CS0', '01667781'),\n",
       "  ('ser', 'VSIP3S0', '01775973'),\n",
       "  ('gimnasia', 'NP00000', '00275488'),\n",
       "  ('y', 'CC', '0'),\n",
       "  ('esgrima_la_plata_de_la_primera_división_de_argentina', 'NP00000', '0'),\n",
       "  ('.', 'Fp', '0')],\n",
       " [('trayectoria', 'NP00000', '06709272'), ('.', 'Fp', '0')],\n",
       " [('debutar', 'VMIS3S0', '01176337'),\n",
       "  ('en', 'SPS00', '0'),\n",
       "  ('1', 'AO0FS0', '02098880'),\n",
       "  ('el', 'DA0MS0', '0'),\n",
       "  ('frente_a', 'SPS00', '0'),\n",
       "  ('river_plate', 'NP00000', '0'),\n",
       "  ('entrar', 'VMG0000', '01376901'),\n",
       "  ('desde', 'SPS00', '0'),\n",
       "  ('el', 'DA0MS0', '0'),\n",
       "  ('banco', 'NCMS000', '06739486'),\n",
       "  ('de', 'SPS00', '0'),\n",
       "  ('suplente', 'NCCP000', '04401363'),\n",
       "  ('a', 'SPS00', '0'),\n",
       "  ('el', 'DA0MP0', '0'),\n",
       "  ('31', 'Z', '0'),\n",
       "  ('minuto', 'NCMP000', '10943650'),\n",
       "  ('de', 'SPS00', '0'),\n",
       "  ('el', 'DA0MS0', '0'),\n",
       "  ('2', 'AO0MS0', '02099012'),\n",
       "  ('tiempo', 'NCMS000', '10850147'),\n",
       "  ('.', 'Fp', '0')]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc_backward = defaultdict(list)\n",
    "dicc_forward = defaultdict(list)\n",
    "for s in check:\n",
    "    for i,w in enumerate(s):\n",
    "        if i != 0:\n",
    "            dicc_backward[w[0]].append((s[i-1][0], s[i-1][1]))\n",
    "        else:\n",
    "            dicc_backward[w[0]].append(('[W.Start]', '[T.Start]'))\n",
    "        if i != len(s)-1:\n",
    "            dicc_forward[w[0]].append((s[i+1][0], s[i+1][1]))\n",
    "        else:\n",
    "            dicc_forward[w[0]].append(('[W.End]', '[T.End]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('river_plate', 'NP00000'), ('el', 'DA0MS0')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc_backward['entrar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('desde', 'SPS00'), ('a', 'SPS00')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc_forward['entrar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc = dict()\n",
    "vec = dict()\n",
    "for fst,snd,trd in words:\n",
    "    features = defaultdict(int)\n",
    "    pos = 'PoS__' + snd\n",
    "    if fst not in dicc and fst not in {'.', ',', ':', ';'} and fst.isalpha() and count[fst] > 1 and trd != 0:\n",
    "        dicc[fst] = features\n",
    "        vec[fst] = trd\n",
    "        features[pos] = 1\n",
    "        for i in dicc_backward[fst]:\n",
    "            features[i[0]+\"-1\"] += 1\n",
    "            features[i[1]+\"-1\"] += 1\n",
    "        for i in dicc_forward[fst]:\n",
    "            features[i[0]+\"+1\"] += 1\n",
    "            features[i[1]+\"+1\"] += 1\n",
    "        \n",
    "    elif fst in dicc:\n",
    "        if trd not in vec[fst]:\n",
    "            dicc[fst] = features\n",
    "            vec[fst] = trd\n",
    "            for i in dicc_backward[fst]:\n",
    "                features[i[0]+\"-1\"] += 1\n",
    "                features[i[1]+\"-1\"] += 1\n",
    "            for i in dicc_forward[fst]:\n",
    "                features[i[0]+\"+1\"] += 1\n",
    "                features[i[1]+\"+1\"] += 1\n",
    "        has_it = dicc[fst]\n",
    "        if pos in has_it:\n",
    "            has_it[pos] += 1\n",
    "        else:\n",
    "            has_it[pos] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'1-1': 1,\n",
       "             '35+1': 1,\n",
       "             'AQ0CS0-1': 3,\n",
       "             'AQ0FP0-1': 1,\n",
       "             'AQ0FS0-1': 3,\n",
       "             'AQ0MP0-1': 1,\n",
       "             'DA0FS0+1': 6,\n",
       "             'DA0MP0+1': 2,\n",
       "             'DA0MS0+1': 3,\n",
       "             'DA0NS0+1': 1,\n",
       "             'DI0FS0+1': 3,\n",
       "             'DI0MP0+1': 1,\n",
       "             'DI0MS0+1': 2,\n",
       "             'DP3CS0+1': 3,\n",
       "             'NCFP000+1': 2,\n",
       "             'NCFP000-1': 2,\n",
       "             'NCFS000+1': 1,\n",
       "             'NCFS000-1': 6,\n",
       "             'NCMN000+1': 1,\n",
       "             'NCMP000+1': 3,\n",
       "             'NCMP000-1': 1,\n",
       "             'NCMS000+1': 3,\n",
       "             'NCMS000-1': 5,\n",
       "             'NP00000+1': 8,\n",
       "             'NP00000-1': 6,\n",
       "             'PR0CS000+1': 1,\n",
       "             'PoS__SPS00': 41,\n",
       "             'RG-1': 1,\n",
       "             'VMII1S0-1': 1,\n",
       "             'VMIP1S0-1': 1,\n",
       "             'VMIP3P0-1': 1,\n",
       "             'VMIP3S0-1': 5,\n",
       "             'VMN0000-1': 1,\n",
       "             'VMP00SF-1': 1,\n",
       "             'VSIP3S0-1': 1,\n",
       "             'Z+1': 1,\n",
       "             'Z-1': 1,\n",
       "             'activo-1': 1,\n",
       "             'agustina_venzano+1': 1,\n",
       "             'agustina_venzano-1': 1,\n",
       "             'alfonsín-1': 1,\n",
       "             'alguno+1': 1,\n",
       "             'angular-1': 1,\n",
       "             'antigüedad-1': 1,\n",
       "             'arco+1': 1,\n",
       "             'bala-1': 1,\n",
       "             'balcón+1': 1,\n",
       "             'balcón-1': 1,\n",
       "             'bien-1': 1,\n",
       "             'bilbao-1': 1,\n",
       "             'bomba+1': 1,\n",
       "             'casar-1': 1,\n",
       "             'cine-1': 1,\n",
       "             'clásico-1': 1,\n",
       "             'común-1': 1,\n",
       "             'conectar-1': 1,\n",
       "             'contar-1': 3,\n",
       "             'cross+1': 1,\n",
       "             'cubo+1': 1,\n",
       "             'cubrir-1': 1,\n",
       "             'cuenta-1': 1,\n",
       "             'dar-1': 1,\n",
       "             'decoración+1': 1,\n",
       "             'desarrollo+1': 1,\n",
       "             'doris_suchecki+1': 1,\n",
       "             'el+1': 12,\n",
       "             'escudo-1': 1,\n",
       "             'etapa-1': 1,\n",
       "             'excipiente+1': 1,\n",
       "             'exito-1': 1,\n",
       "             'experiencia-1': 2,\n",
       "             'finlandés-1': 1,\n",
       "             'ganador-1': 1,\n",
       "             'gótico-1': 1,\n",
       "             'kansas-1': 1,\n",
       "             'modificar-1': 1,\n",
       "             'obtener-1': 1,\n",
       "             'pilar_manzanares+1': 1,\n",
       "             'quien+1': 1,\n",
       "             'rata-1': 1,\n",
       "             'realengo-1': 1,\n",
       "             'recinto-1': 1,\n",
       "             'regidor+1': 1,\n",
       "             'san_la_muerte-1': 1,\n",
       "             'ser-1': 1,\n",
       "             'sergio_joselovsky+1': 2,\n",
       "             'software+1': 1,\n",
       "             'su+1': 3,\n",
       "             'sublime-1': 1,\n",
       "             'séneca+1': 1,\n",
       "             'trayectoria+1': 1,\n",
       "             'trespaderne+1': 1,\n",
       "             'uno+1': 5,\n",
       "             'vida-1': 1,\n",
       "             'vivir-1': 1,\n",
       "             'wesley-1': 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicc['con']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "vector = []\n",
    "final_check = []\n",
    "for key, value in dicc.items():    #preparo la lista de dicts y la lista de chequeo para recuperar el nombre al final\n",
    "    final_check.append(key)\n",
    "    matrix.append(value)\n",
    "for key, value in vec.items():       #vector de synsets\n",
    "    vector.append(int(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer()\n",
    "X = v.fit_transform(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_k = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best = mejor_k[1]*0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################Supervisada, clase: synset ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = SelectKBest(chi2, k=int(k_best)).fit_transform(X, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalización\n",
    "import sklearn\n",
    "Y = sklearn.preprocessing.normalize(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=15, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=15)\n",
    "km.fit(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = km.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {13: {'directo', 'crear', 'ambos', 'participar', 'morir', 'transformar', 'destacar', 'aceptar', 'vivir', 'apreciar', 'mediocampista', 'utilizar', 'el', 'tipo', 'filmar', 'realizar', 'numeroso', 'vengar', 'representar', 'asesinar', 'tomar', 'uno', 'otro', 'imitar', 'español', 'publicar', 'hacer', 'mi', 'su', 'varios', 'moderno'}, 2: {'revista', 'importancia', 'canción', 'cual', 'localidad', 'forma', 'acción', 'masa', 'organización', 'aparición', 'banda', 'falta', 'traducción', 'píldora', 'escena', 'información', 'hora', 'ilustración', 'versión', 'lengua', 'fraternidad', 'bomba', 'ciudad', 'voz', 'provincia', 'plata', 'comarca', 'parroquia', 'sociedad', 'razón', 'oportunidad'}, 7: {'la', 'jökulsárlón', 'cross', 'centralita', 'bond', 'grecia', 'américa', 'sloan', 'castelao', 'ecu', 'youtube', 'nightwish', 'medicina', 'holopainen', 'enlaces', 'francia', 'descripción', 'endofarticle', 'referencias', 'mcavoy', 'españa', 'bibliografía', 'nadie', 'wanted', 'islandia', 'höfn', 'hip', 'mendoza', 'praga', 'gimnasia', 'fox', 'himeto', 'peramola', 'argentina', 'wesley', 'timur'}, 10: {'estrenar', 'estadounidense', 'pasar', 'ser', 'todo', 'dejar', 'escribir', 'atravesar', 'o', 'dar', 'aunque', 'confirmar', 'resaltar', 'y', 'médico', 'incluir', 'pero', 'igual', 'lanzar', 'seguir', 'nacer'}, 8: {'clásico', 'acústico', 'mentira', 'especial', 'único', 'finlandés', 'completo', 'farmacéutico', 'planetario', 'público', 'corto', 'moralista', 'verdadero', 'futuro', 'político', 'nuevo', 'complejo', 'literario', 'ex', 'futbolista', 'rico', 'solo', 'gran', 'central'}, 4: {'mismo', 'niño', 'tejido', 'frase', 'hijo', 'asesino', 'habitante', 'problema', 'sensor', 'externo', 'presente', 'año', 'individuo', 'altura', 'punto', 'relato', 'pueblo', 'actor', 'editar', 'actuador', 'argentino', 'mejor', 'mayor', 'entrenamiento', 'iceberg', 'medio'}, 3: {'antiguo', 'puerta', 'poco', 'aparecer', 'tener', 'casa', 'ver', 'actuación', 'alguno', 'estar', 'los', 'datos', 'jugar', 'enlace', 'obra', 'fábrica', 'este', 'característica', 'listar', 'cousas', 'existir', 'nuncarga', 'si', 'polígono', 'Finalmente', 'situación', 'cada', 'historia', 'comprimir', 'nuestro', 'trayectoria'}, 5: {'hacia', 'a', 'sin', 'por', 'bajo', 'desde', 'de', 'para', 'con', 'sobre', 'durante', 'hasta', 'según', 'en', 'tras', 'entre'}, 1: {'gol', 'ayuntamiento', 'anillo', 'estilo', 'municipio', 'vehículo', 'tiempo', 'patrimonio', 'inglés', 'álbum', 'sector', 'término', 'booklet', 'pecado', 'vídeo', 'equipo', 'automóvil', 'tamaño', 'valor', 'lirismo', 'tren', 'nombre', 'partido', 'premio', 'propio', 'lago', 'momento', 'trabajo', 'río', 'mundo', 'glaciar', 'humor', 'video', 'canal', 'reparto', 'último', 'entorno', 'gas', 'escritor', 'cine', 'padre', 'día', 'marco', 'azul', 'sistema', 'puente', 'control', 'cómic', 'sur', 'color', 'autor', 'ruso', 'monte', 'single', 'terreno', 'auto'}, 0: {'lo', 'solar', 'porque', 'decir', 'declarar', 'reconocer', 'grande', 'cuadrar', 'haber', 'nada', 'conocer', 'yo', 'cuando', 'oír', 'donde', 'oral', 'te', 'que', 'actual', 'llamar', 'poder', 'escoger', 'general', 'etcétera', 'quien', 'skuas', 'le', 'joven', 'industrial', 'les', 'descubrir', 'como', 'querer', 'encontrar', 'ese', 'se', 'cuyo', 'quién', 'breve', 'jamar', 'creer', 'necesario'}, 9: {'llegar', 'situar', 'mudar', 'entrar', 'comenzar', 'adosar', 'revelar', 'conectar', 'llevar', 'producir', 'ingresar', 'tender', 'presentar', 'gritar', 'pues', 'rodear', 'perseguir', 'venir', 'confusión', 'contar', 'ir', 'matar', 'controlar', 'aprender', 'abrir'}, 14: {'escudo', 'moral', 'toque', 'activo', 'oficial', 'artículo', 'estudio', 'salir', 'rojo', 'americano', 'tratar', 'iglesia', 'habilidad', 'formar', 'electrónico', 'típico', 'grabar', 'dibujo', 'sinónimo', 'blanco', 'usar', 'generación', 'cinematográfico', 'arco', 'trabajar', 'dirigir', 'plan', 'convertir', 'terminar', 'comprender', 'proporcionar', 'minuto', 'rata', 'recibir'}, 12: {'entonces', 'sólo', 'especialmente', 'ahí', 'más', 'muy', 'menos', 'probablemente', 'así', 'ya', 'también', 'además', 'bien', 'siempre', 'finalmente'}, 11: {'parte', 'verdad', 'carta', 'mujer', 'educación', 'película', 'experiencia', 'nebulosa', 'the', 'tableta', 'secuela', 'duración', 'cápsula', 'manera', 'naturaleza', 'persona', 'bala', 'luz', 'zona', 'estrella', 'vez', 'radio', 'tejedor', 'planta', 'vida', 'intercomunicación', 'mampostería', 'pastilla', 'carretera', 'sillería', 'orilla', 'época', 'muerte', 'etapa', 'página'}, 6: {'deber', 'ejecutar', 'allí', 'luego', 'él', 'no'}})\n"
     ]
    }
   ],
   "source": [
    "clusters = defaultdict(set)\n",
    "for i, label in enumerate(labels):\n",
    "    clusters[label].add(final_check[i])\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
